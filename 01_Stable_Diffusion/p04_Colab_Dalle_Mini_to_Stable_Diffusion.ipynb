{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0106efd9",
      "metadata": {
        "id": "0106efd9"
      },
      "source": [
        "Josh and I have talked about using Stable Diffusion to generate a new version of the logo on our\n",
        "landing page every day. Stable diffusion alone hasn't been able to generate anything meaningful, but\n",
        "let's try creating seed images with DalleMini and then use Stable Diffusion img2img to refine them.\n",
        "\n",
        "_Based on: https://github.com/huggingface/diffusers/blob/main/README.md#image-to-image-text-guided-generation-with-stable-diffusion_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e542ca8e",
      "metadata": {
        "id": "e542ca8e"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/run-house/runhouse.git@latest_patch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import runhouse as rh\n",
        "import torch\n",
        "from PIL import Image\n",
        "import random"
      ],
      "metadata": {
        "id": "-zDuo8-p6UEm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d576e496-3fa6-40f9-b0f4-f9968fd050ee"
      },
      "id": "-zDuo8-p6UEm",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO | 2022-12-21 08:40:20,340 | Loaded Runhouse config from /root/.rh/config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!runhouse login"
      ],
      "metadata": {
        "id": "aowBJm1dqdiD"
      },
      "id": "aowBJm1dqdiD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_WFF9nyRtCB"
      },
      "source": [
        "### Login to Runhouse to load in secrets."
      ],
      "id": "2_WFF9nyRtCB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UnHVWUYplGV"
      },
      "outputs": [],
      "source": [
        "# You can add token=<your token> if you want to be able to run this without pasting into stdin\n",
        "rh.login(download_secrets=True, download_config=True)"
      ],
      "id": "5UnHVWUYplGV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3G8NcBOUF4sb"
      },
      "outputs": [],
      "source": [
        "# Only if you're using GCP and running inside Colab!\n",
        "!gcloud init\n",
        "!gcloud auth application-default login\n",
        "!cp -r /content/.config/* ~/.config/gcloud"
      ],
      "id": "3G8NcBOUF4sb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0s_uGZSssCrV"
      },
      "outputs": [],
      "source": [
        "# Check that secrets are loaded in properly and at least one cloud is ready to use.\n",
        "!sky check"
      ],
      "id": "0s_uGZSssCrV"
    },
    {
      "cell_type": "markdown",
      "id": "9eded113",
      "metadata": {
        "id": "9eded113"
      },
      "source": [
        "First try just DalleMini. It runs best on an A100, but AWS doesn't offer single A100s (only clusters of 8),\n",
        "so let's run it on gcp.\n",
        "gcp_gpu = rh.cluster(name='a100', instance_type='A100:1', provider='gcp', use_spot=False, autostop_mins=60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "874c5c74",
      "metadata": {
        "id": "874c5c74"
      },
      "outputs": [],
      "source": [
        "def dm_generate(prompt, num_images_sqrt=1, supercondition_factor=32, is_mega=True, seed=50, top_k=64):\n",
        "    from min_dalle import MinDalle\n",
        "    import torch\n",
        "    from PIL import Image\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.no_grad()\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    torch.backends.cuda.matmul.allow_fp16_reduced_precision_reduction = True\n",
        "    dalle = MinDalle(device='cuda', is_mega=is_mega, is_reusable=False, dtype=torch.float16)\n",
        "    images = dalle.generate_images(prompt, seed=seed, grid_size=num_images_sqrt,\n",
        "                                   temperature=1, top_k=top_k, supercondition_factor=supercondition_factor)\n",
        "    images = images.to(torch.uint8).to('cpu').numpy()\n",
        "    return [Image.fromarray(images[i]) for i in range(num_images_sqrt**2)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gcp_gpu = rh.cluster(name='a100', instance_type='A100:1', provider='gcp', use_spot=False)\n",
        "# gcp_gpu = rh.cluster(name='a10g', instance_type='A10G:1', provider='cheapest', use_spot=False)\n",
        "dm_generate_gpu = rh.send(fn=dm_generate, \n",
        "                          hardware=gcp_gpu,\n",
        "                          reqs=['./', 'torch', 'min-dalle'],\n",
        "                          load_from=['rns'], save_to=['rns'],\n",
        "                          name='dm_generate')"
      ],
      "metadata": {
        "id": "9JyKm4SiL6om"
      },
      "id": "9JyKm4SiL6om",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0a5b44a",
      "metadata": {
        "id": "d0a5b44a"
      },
      "outputs": [],
      "source": [
        "rh_prompt = 'A digital illustration of a woman running on the roof of a house.'\n",
        "\n",
        "seed = random.randint(0, 1000)\n",
        "rh_logo_dm_images = dm_generate_gpu(rh_prompt, \n",
        "                                    seed=seed,\n",
        "                                    is_mega=False,\n",
        "                                    num_images_sqrt=2,\n",
        "                                    supercondition_factor=256)\n",
        "[image.show() for image in rh_logo_dm_images]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12d3e900",
      "metadata": {
        "id": "12d3e900"
      },
      "source": [
        "Now let's try feeding it into StableDiffusionImg2Img. We could put this on a the A100, but it might OOM,\n",
        "so let's put it on a V100 on AWS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b962a5b",
      "metadata": {
        "scrolled": false,
        "id": "5b962a5b"
      },
      "outputs": [],
      "source": [
        "def sd_img2img_generate(prompt, base_images, num_images=1,\n",
        "                        steps=100, strength=0.75, guidance_scale=7.5, model_id=\"stabilityai/stable-diffusion-2-base\"):\n",
        "    from diffusers import StableDiffusionImg2ImgPipeline\n",
        "    import torch\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.no_grad()\n",
        "    sd_pipe = StableDiffusionImg2ImgPipeline.from_pretrained(model_id)\n",
        "    sd_pipe = sd_pipe.to('cuda')\n",
        "    ret = []\n",
        "    for image in base_images:\n",
        "        ret = ret + sd_pipe([prompt] * num_images, init_image=image.resize((512, 512)),\n",
        "                            num_inference_steps=steps, strength=strength,\n",
        "                            guidance_scale=guidance_scale).images\n",
        "    return ret\n",
        "\n",
        "sd_img2img_generate_gpu = rh.send(fn=sd_img2img_generate, hardware='a100',\n",
        "                                  reqs=['./', 'transformers', 'diffusers'],\n",
        "                                  load_secrets=True,\n",
        "                                  load_from=['rns'], save_to=['rns'],\n",
        "                                  name='sd_img2img_generate')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a328f751",
      "metadata": {
        "id": "a328f751"
      },
      "outputs": [],
      "source": [
        "rh_logo_dm2sd_images = sd_img2img_generate_gpu(rh_prompt, rh_logo_dm_images, strength=.75,\n",
        "                                               guidance_scale=7.5, steps=25)\n",
        "[image.show() for image in rh_logo_dm2sd_images]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea94bd81",
      "metadata": {
        "id": "ea94bd81"
      },
      "source": [
        "Now let's do a tester passing an existing runhouse logo image to SDImg2Img."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3cab4b0",
      "metadata": {
        "id": "c3cab4b0"
      },
      "outputs": [],
      "source": [
        "rh_base_image = Image.open('rh_logo.png').convert(\"RGB\").resize((512, 512))\n",
        "rh_logo_sd_images = sd_img2img_generate_gpu(rh_prompt, [rh_base_image],\n",
        "                                            strength=.5, guidance_scale=5,\n",
        "                                            num_images=2, steps=100)\n",
        "[display(image) for image in rh_logo_sd_images]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}